# hw5_1

# 1
## 1.1
### 1.1.1
[1024, 1024]
### 1.1.2
[8, 128, 1024]
### 1.1.3
[8, 128, 1024]
All-Gather 将各rank的输出在最后一个维度上拼接得到完整的 Y.shape = [8, 128, 4096]

## 1.2
### 1.2.1
[1024, 1024]
### 1.2.2
[8, 128, 1024]
### 1.2.3
[8, 128, 1024]
All-Reduce 将各 rank 的输出求和得到完整的 Z.shape = [8, 128, 1024]

# 2
## 2.1
### 2.1.1
不需要通信
### 2.1.2
需要通信
每个rank只有部分权重，而计算完整的输入梯度需要所有的权重信息
通信量：8 * 128 * 1024

## 2.2
### 2.2.1
需要通信
All-Reduce
通信量：8 * 128 * 1024
### 2.2.2
不需要通信

# 3
## 都使用Row Parallel
Linear1输出需要All-Reduce聚合成完整结果，然后需要重新按行切分给Linear2使用，需要额外的 B * S * 4D 的通信
## 都使用Column Parallel
带来的问题是维度不匹配和数据重分布。